{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso,LassoCV,LinearRegression,Ridge\n",
    "from sklearn.decomposition import TruncatedSVD, KernelPCA, PCA\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import AdaBoostRegressor,BaggingRegressor, RandomForestRegressor\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from math import sqrt,atan2,pi,ceil,acos,sin,cos\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "from orelmisc import n_max,n_test_max,testpre,trainpre,saveCSV,shape_3d_org\n",
    "from preprocess import flatten,flatten_each_sample,loadData,flatten_each_sample,precompute_and_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prep_ = lambda i: cap(i)\n",
    "def prep(a):\n",
    "  return map(prep_single,a)\n",
    "\n",
    "prep_single = lambda pi:map(prep_,pi)\n",
    "\n",
    "cap = lambda p: 0 if min(1,max(0,p)) < 0.5 else 1\n",
    "def pred_to_rgb(p):\n",
    "  p = cap(p)\n",
    "  v = p\n",
    "  return (1-v,v,0.2)\n",
    "\n",
    "y = np.zeros((n_max,3))\n",
    "# gender: 1 = female, 0 = male\n",
    "# age: 1 = young, 0 = old\n",
    "# health: 1 = healthy, 0 = sick\n",
    "y_gender = [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "y_age = [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "y_health = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "y[:,0] = np.array(y_gender)\n",
    "y[:,1] = np.array(y_age)\n",
    "y[:,2] = np.array(y_health)\n",
    "\n",
    "result = None\n",
    "xa = []\n",
    "x = None\n",
    "x_t = None\n",
    "TO_RADIANS = pi/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Histograms: 144\n",
      "Size of Histograms: 69\n",
      "Dimensions: ca. 9936\n"
     ]
    }
   ],
   "source": [
    "space = 70 #35 # 35,50,70,100,150\n",
    "bins = np.linspace(1,1700,space)\n",
    "hSize = space-1\n",
    "r_division = 6\n",
    "theta_division = 4\n",
    "phi_division = 6\n",
    "ranges = [1,r_division,theta_division,phi_division]\n",
    "nHists = r_division*theta_division*phi_division\n",
    "\n",
    "# IDEA:\n",
    "# * take a look at the empirical distribution (Anteile) of the predicted classes.\n",
    "#   All the real-valued predictions can be plotted in a 3D plot :)\n",
    "#   If there are too few (many) predictions in a class (by comparision to Anteile in training set),\n",
    "#   then move the closest other samples to our class (furthest of current samples to another class).\n",
    "\n",
    "name = \"output/\"+str(space)+\"_split_validated\"\n",
    "fname = \"many_hists\"+str(nHists)+\"_space\" + str(space) + (\"_divs_%s_%s_%s.npy\" % (r_division,theta_division,phi_division))\n",
    "fnameSpherical = \"spherical_every2.npy\"\n",
    "fnameMeanHist = \"mean_hist\" + str(space) + \".npy\"\n",
    "fnameMeanHists = \"mean_hists\" + str(space) + \".npy\"\n",
    "\n",
    "xSpherical = np.load(fnameSpherical)\n",
    "sbins = bins[:-1]+1800/space/2\n",
    "ds = nHists*hSize # sum,sum2,sum3,avg,var,mode, numper of percentiles and histograms\n",
    "iHist = 0\n",
    "idxHist = lambda i: iHist+i*hSize\n",
    "# radius form 0 to 80\n",
    "# theta from 0 to 180\n",
    "# phi from 0 to 360\n",
    "rMax = 80\n",
    "tMin = 30\n",
    "tMax = 180-tMin\n",
    "\n",
    "print \"Number of Histograms:\",nHists\n",
    "print \"Size of Histograms:\",hSize\n",
    "print \"Dimensions: ca.\",nHists*hSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myloop(a):\n",
    "    return (a,a*a,a*a*a)\n",
    "\n",
    "def spherical2cart(r,theta,phi):\n",
    "  return (r*sin(theta)*cos(phi),r*sin(theta)*sin(phi),r*cos(theta))\n",
    "\n",
    "myloopU = np.frompyfunc(myloop,1,3,dtype=np.float64)\n",
    "fromto = lambda di,sph: zip(np.round(np.linspace(0,sph.shape[di],ranges[di]+1)),np.round(np.linspace(0,sph.shape[di],ranges[di]+1))[1:])\n",
    "\n",
    "def loadAndPreprocess():\n",
    "    global d_org,x,x_t,xa,x_org,x_t_org,xa_org,xSpherical\n",
    "    \n",
    "    xa = np.zeros((n_max+n_test_max,ds))\n",
    "    #xSpherical = np.zeros((n_max+n_test_max,rMax/2+1,(tMax-tMin)/2+1,360/2+1))\n",
    "    \n",
    "    i = 0\n",
    "    #print \"===== Calculate spherical coordiantes ====\"\n",
    "    \n",
    "    while i < n_max+n_test_max:\n",
    "      if i % 6 == 0:\n",
    "        print \"  i = %s ... %.1f%%\" % (i,float(i)/(n_max+n_test_max)*100)\n",
    "      \n",
    "      n_i,pre,t_str = (n_max,\"set_train/\",\"train\") if i < n_max else (n_test_max,\"set_test/\",\"test\")\n",
    "      filename = \"%s%s_%s.nii\" % (pre,t_str,i%n_max+1)\n",
    "      Xtotal,Ytotal,Ztotal = (176,208,176)\n",
    "      data = nib.load(filename).get_data().reshape((Xtotal,Ytotal,Ztotal))\n",
    "      \n",
    "      \"\"\"Calculate zoomed spherical representation, needs 3 seconds\n",
    "      for r in np.linspace(0,rMax,rMax/2+1):\n",
    "        for theta in np.linspace(tMin,tMax,(tMax-tMin)/2+1):\n",
    "          for phi in np.linspace(0,360,360/2+1):\n",
    "            x,y,z = spherical2cart(r,theta*TO_RADIANS,phi*TO_RADIANS)\n",
    "            x = x + Xtotal/2\n",
    "            y = y + Ytotal/2\n",
    "            z = z + Ztotal/2\n",
    "            if 0 <= x < Xtotal and 0 <= y < Ytotal and 0 <= z < Ztotal:\n",
    "              xSpherical[i,r/2,(theta-tMin)/2,phi/2] = data[int(x),int(y),int(z)]\"\"\"\n",
    "\n",
    "      # calculate histograms: 8*4*8 = 256 histograms\n",
    "      hCount = 0\n",
    "      for l,u in fromto(1,xSpherical):\n",
    "        l0,u0=(int(l),int(u))\n",
    "        for l,u in fromto(2,xSpherical):\n",
    "          l1,u1=(int(l),int(u))\n",
    "          for l,u in fromto(3,xSpherical):\n",
    "            l2,u2=(int(l),int(u))\n",
    "            cut = xSpherical[i,l0:u0,l1:u1,l2:u2]\n",
    "            h=np.histogram(cut.ravel(),bins=bins)[0]\n",
    "            xa[i,(iHist+(hCount*hSize)):(iHist+(hCount+1)*hSize)] = h\n",
    "            hCount = hCount + 1\n",
    "      i = i+1\n",
    "    \n",
    "    np.save(fname,xa)\n",
    "    print \"======= Saved data matrix xa into %s =========\" % fname\n",
    "    \n",
    "    #np.save(fnameSpherical,xSpherical)\n",
    "    #print \"======= Saved spherical coordinates into %s =========\" % fnameSpherical\n",
    "\n",
    "if False:\n",
    "  loadAndPreprocess()\n",
    "else:\n",
    "  xa = np.load(fname)\n",
    "  x,x_t = (xa[0:n_max,:],xa[n_max:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  i = 413\n",
    "  for theta in np.linspace(0,xSpherical[i].shape[1]-1,9):\n",
    "    print theta\n",
    "    plt.imshow(xSpherical[i,:,theta,:], cmap=\"gray\", origin=\"lower\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public Training contains 278 samples of total 278 : 100.00%\n",
      "  10.07%: [0, 0, 0] with samples: #28\n",
      "  6.47%: [0, 0, 1] with samples: #18\n",
      "  0.00%: [0, 1, 0] with samples: #0\n",
      "  22.30%: [0, 1, 1] with samples: #62\n",
      "  14.03%: [1, 0, 0] with samples: #39\n",
      "  17.27%: [1, 0, 1] with samples: #48\n",
      "  0.00%: [1, 1, 0] with samples: #0\n",
      "  29.86%: [1, 1, 1] with samples: #83\n",
      "our Training contains 192 samples of total 192 : 100.00%\n",
      "  9.90%: [0, 0, 0] with samples: #19\n",
      "  6.25%: [0, 0, 1] with samples: #12\n",
      "  0.00%: [0, 1, 0] with samples: #0\n",
      "  22.40%: [0, 1, 1] with samples: #43\n",
      "  14.06%: [1, 0, 0] with samples: #27\n",
      "  17.19%: [1, 0, 1] with samples: #33\n",
      "  0.00%: [1, 1, 0] with samples: #0\n",
      "  30.21%: [1, 1, 1] with samples: #58\n",
      "our Test contains 86 samples of total 86 : 100.00%\n",
      "  10.47%: [0, 0, 0] with samples: #9\n",
      "  6.98%: [0, 0, 1] with samples: #6\n",
      "  0.00%: [0, 1, 0] with samples: #0\n",
      "  22.09%: [0, 1, 1] with samples: #19\n",
      "  13.95%: [1, 0, 0] with samples: #12\n",
      "  17.44%: [1, 0, 1] with samples: #15\n",
      "  0.00%: [1, 1, 0] with samples: #0\n",
      "  29.07%: [1, 1, 1] with samples: #25\n",
      "Splitted data into test and validation data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xa. all data\n",
    "# x. public training data\n",
    "# y. public training targets\n",
    "# x_t public to be predicted data\n",
    "\n",
    "# xtr. training data\n",
    "# ytr. training targets\n",
    "# xts. validation data\n",
    "# yts. validation targets\n",
    "\n",
    "b = [0,1]\n",
    "types = [ [a1,a2,a3] for a1 in b for a2 in b for a3 in b]\n",
    "Ntypes = len(types)\n",
    "\n",
    "def get_by(t,ys):\n",
    "    idxs = range(0,len(ys))\n",
    "    return filter(lambda i:list(ys[i,:])==list(t),idxs)\n",
    "\n",
    "#indices for splitting\n",
    "typeIdxs = [get_by(t,y) for t in types]\n",
    "\n",
    "typeIdxsTR = []\n",
    "typeIdxsTS = []\n",
    "\n",
    "for i in range(0,Ntypes):\n",
    "    atr,ats,_,_ = train_test_split(typeIdxs[i],np.zeros(len(typeIdxs[i])),test_size=0.3,random_state=1)\n",
    "    typeIdxsTR.append(atr)\n",
    "    typeIdxsTS.append(ats)\n",
    "    \n",
    "typeIdxs = np.array(typeIdxs)\n",
    "typeIdxsTR = np.array(typeIdxsTR)\n",
    "typeIdxsTS = np.array(typeIdxsTS)\n",
    "\n",
    "# gender: 1 = female, 0 = male\n",
    "# age: 1 = young, 0 = old\n",
    "# health: 1 = healthy, 0 = sick\n",
    "\n",
    "def show_diff_for(name,es1,es2,total):\n",
    "  es = map(lambda x,y:x-y,es1,es2)\n",
    "  abses = map(abs,es)\n",
    "  print name,\"contains\",sum(abses),\"samples of total\",total,\": %0.2f%%\" % (100*float(sum(abses))/total)\n",
    "  for i in range(0,8):\n",
    "      tp = ((100*float(es[i])/total),types[i],es[i])\n",
    "      print \"  %0.2f%%: %s with samples: #%s\" % tp\n",
    "      \n",
    "def show_diff(name,es1,es2):\n",
    "  es1 = map(len,es1)\n",
    "  es2 = map(len,es2)\n",
    "  show_diff_for(name,es1,es2,total=sum(es1))\n",
    "        \n",
    "def show_for(name,es):\n",
    "  es1 = map(lambda x:len(x),es)\n",
    "  show_diff_for(name,es1,[0]*8,sum(es1))\n",
    "\n",
    "show_for(\"public Training\",typeIdxs)\n",
    "show_for(\"our Training\",typeIdxsTR)\n",
    "show_for(\"our Test\",typeIdxsTS)\n",
    "\n",
    "xtr = np.vstack([x[idxs]for idxs in typeIdxsTR])\n",
    "xts = np.vstack([x[idxs]for idxs in typeIdxsTS])\n",
    "ytr = np.vstack([y[idxs]for idxs in typeIdxsTR])\n",
    "yts = np.vstack([y[idxs]for idxs in typeIdxsTS])\n",
    "\n",
    "print \"Splitted data into test and validation data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def applySingleClassification(classf,label):\n",
    "  prefix_str,model = classf\n",
    "  xtr1 = xtr[:,:]\n",
    "  xts1 = xts[:,:]\n",
    "  x_t1 = x_t[:,:]\n",
    "  \n",
    "  yts_pred = model.fit(xtr1,ytr[:,label]).predict(xts1)\n",
    "  y_t_pred = model.predict(x_t1)\n",
    "  \n",
    "  y_t_pp = prep_single(y_t_pred)\n",
    "  yts_pp = prep_single(yts_pred)\n",
    "  ytr_pp = prep_single(model.predict(xtr1))\n",
    "  \n",
    "  trCorrect = len(filter(lambda x:x,map(lambda x,y:x==y,ytr[:,label],ytr_pp)))\n",
    "  tsCorrect = len(filter(lambda x:x,map(lambda x,y:x==y,yts[:,label],yts_pp)))\n",
    "  ltr = 100*hamming_loss(ytr[:,label],ytr_pp)\n",
    "  lts = 100*hamming_loss(yts[:,label],yts_pp)\n",
    "  \n",
    "  print \"|   %3d    /    %3d    |   %3d   /     %3d    |    %3.1f%%     |     %3.1f%%     |\" % (trCorrect,len(xtr)-trCorrect,tsCorrect,len(xts)-tsCorrect,ltr,lts)\n",
    " #print \"|  correct / incorrect | correct / incorrect | Hamming Loss | lts =        |\"\n",
    "  return model,y_t_pp,yts_pp,ltr,lts\n",
    "\n",
    "def applyClassificationSeparated(classf):\n",
    "  prefix = classf[0]\n",
    "  # TODO: copy output to file\n",
    "  print \"### Prediction with ###\\n\",\"  \",prefix,\"\\n\"\n",
    "  \n",
    "  print \"| Predictions training | Predictions test     | Hamming Loss | Hamming Loss |\"\n",
    "  print \"|  correct / incorrect | correct / incorrect  |   Training   |    Test      |\"\n",
    "  \n",
    "  model1,y_gender_pred,ytspp1,ltr1,lts1 = applySingleClassification(classf,0)\n",
    "  model2,y_age_pred   ,ytspp2,ltr2,lts2 = applySingleClassification(classf,1)\n",
    "  model3,y_health_pred,ytspp3,ltr3,lts3 = applySingleClassification(classf,2)\n",
    "  \n",
    "  y_pred_all = np.array([y_gender_pred,y_age_pred,y_health_pred]).transpose()\n",
    "  y_pred_ts = np.array([ytspp1,ytspp2,ytspp3]).transpose()\n",
    "  ltr = np.average([ltr1,ltr2,ltr3])\n",
    "  lts = np.average([lts1,lts2,lts3])\n",
    "  \n",
    "  print \"|                     Total                   |    %3.1f%%     |     %3.1f%%     |\" % (ltr,lts)\n",
    "  \n",
    "  return (y_pred_all,y_pred_ts,ltr,lts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doStuff(al=15,comps=n_max-1,n_est=120,k1=\"rbf\",\n",
    "            max_depth=7,msplit=10,feats=0.3,samps=0.3,rs=0,\n",
    "            kernel=\"rbf\",coef0=1,p=False,deg=3,gamma=1.0/600,C=80,n_comps=15,f=0.5,msp=15,hmin=0,hmax=50):\n",
    "  #prefix,model = makeLassoPrediction(al=al)\n",
    "  #prefix,model = makeAdaDefaultBaseEstimatorPrediction(n_est=n_est,max_depth=max_depth,msplit=msplit)\n",
    "  #prefix,model = makeAdaLassoPrediction(al=al,n_est=n_est)\n",
    "  #prefix,model = kernelSVM(kernel=kernel,coef0=coef0,probability=p,degree=deg,gamma=gamma,C=C)\n",
    "  #prefix,model = kernelSVMwithDimReduction(kernel=kernel,k1=k1,coef0=coef0,probability=p,degree=deg,gamma=gamma,C=C,n_comps=n_comps)\n",
    "  #prefix,model = kSVM_Ada(n_est=n_est,kernel=kernel,k1=k1,coef0=coef0,probability=p,degree=deg,gamma=gamma,C=C,n_comps=n_comps)\n",
    "  #prefix,model = makeBaggingBoostLassoPrediction(al=al,n_est=n_est,feats=feats,samps=samps)\n",
    "  #prefix,model = makeSVDLassoPrediction(al=al,comps=comps)\n",
    "  #prefix,model = makeLassoCVPrediction(cv=3)\n",
    "  #prefix,model = makeLinearRegression()\n",
    "  #prefix,model = makeRidgePrediction(al=al)\n",
    "  #prefix,model = makeGaussianProcess()\n",
    "  # Bagging Lasso works poorly when validated and on the public score. forget this.\n",
    "  #prefix,model = makeBaggingBoostLassoPrediction(al=al,n_est=n_est,feats=feats,samps=samps)\n",
    "  \n",
    "  prefix = \"%s_RandomForest_histMin%s_histMax%s_n%s_feats%s_msp%s_max_depth%s\"%(name,hmin,hmax,n_est,f,msp,max_depth)\n",
    "  model = RandomForestRegressor(n_est,max_features=f,min_samples_split=msp,max_depth=max_depth,random_state=rs)\n",
    "  \n",
    "  y_pred_all,y_pred_ts,ltr,lts = applyClassificationSeparated((prefix,model))\n",
    "  \n",
    "  eachX_T = np.array([ get_by(t,y_pred_ts) for t in types])\n",
    "  #show_for(\"our Test\",typeIdxsTS)\n",
    "  #show_for(\"predicted Test\",eachX_T)\n",
    "  show_diff(\"Error\",typeIdxsTS,eachX_T)\n",
    "  \n",
    "  visualize(\"Gender\",y_pred_all[:,0])\n",
    "  visualize(\"Age   \",y_pred_all[:,1])\n",
    "  visualize(\"Health\",y_pred_all[:,2])\n",
    "  \n",
    "  savePrediction(y_pred_all,prefix)\n",
    "  \n",
    "  result = (x,y,x_t,y_pred_all,y_pred_all,y_pred_ts)\n",
    "\n",
    "def visualize(labelName,y_pred):\n",
    "  total = int(len(y_pred)*0.7)\n",
    "  zeros = int(len(filter(lambda x:x == 0,y_pred))*0.7)\n",
    "  print labelName,\" \",\"0\"*zeros,\"#\",\"1\"*(total-zeros),\"***\"\n",
    "\n",
    "def savePrediction(ys,prefix):\n",
    "    savedFilename = saveCSV(ys,prefix)\n",
    "    print(\"Saved predictions into %s\" % savedFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Prediction with ###\n",
      "   output/70_split_validated_RandomForest_histMin0_histMax144_n250_feats0.07_msp10_max_depth3 \n",
      "\n",
      "| Predictions training | Predictions test     | Hamming Loss | Hamming Loss |\n",
      "|  correct / incorrect | correct / incorrect  |   Training   |    Test      |\n",
      "|   186    /      6    |    61   /      25    |    3.1%     |     29.1%     |\n",
      "|   192    /      0    |    78   /       8    |    0.0%     |     9.3%     |\n",
      "|   191    /      1    |    73   /      13    |    0.5%     |     15.1%     |\n",
      "|                     Total                   |    1.2%     |     17.8%     |\n",
      "Error contains 42 samples of total 86 : 48.84%\n",
      "  5.81%: [0, 0, 0] with samples: #5\n",
      "  6.98%: [0, 0, 1] with samples: #6\n",
      "  0.00%: [0, 1, 0] with samples: #0\n",
      "  11.63%: [0, 1, 1] with samples: #10\n",
      "  -11.63%: [1, 0, 0] with samples: #-10\n",
      "  -5.81%: [1, 0, 1] with samples: #-5\n",
      "  0.00%: [1, 1, 0] with samples: #0\n",
      "  -6.98%: [1, 1, 1] with samples: #-6\n",
      "Gender   0000000000 # 11111111111111111111111111111111111111111111111111111111111111111111111111111111111111 ***\n",
      "Age      00000000000000000000000000000000000000000000 # 1111111111111111111111111111111111111111111111111111 ***\n",
      "Health   000000000000000000 # 111111111111111111111111111111111111111111111111111111111111111111111111111111 ***\n",
      "Saved predictions into output/70_split_validated_RandomForest_histMin0_histMax144_n250_feats0.07_msp10_max_depth3.csv\n"
     ]
    }
   ],
   "source": [
    "doStuff(\n",
    "  #kernel=\"poly\",gamma=1.0/2,coef0=1,deg=2,al=9,k1=\"poly\",n_comps=15,C=1,n_est=70,\n",
    "  n_est=250,f=0.07,msp=10,max_depth=3,hmin=0,hmax=nHists,rs=2,\n",
    "  msplit=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
